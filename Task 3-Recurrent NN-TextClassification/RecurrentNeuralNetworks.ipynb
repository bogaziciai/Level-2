{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "Recurrent Neural Networks are used when data is sequential. For example, a video is a sequence of frames, an audio wave is sequence of different amplitutes, or language is a sequence of letters and words. In all those scenarios, every step of data is related with other part of it. Data points are not independent of each other. <br>\n",
    "In order to analyze a series data as a whole, we keep an additional hidden layer, which tracks the \"state\" of the flow. Every datapoint results in two different outputs. While one output is the result output, the other one is the state output which is appended to the next datapoint. <br>\n",
    "For a detailed explanation you can check: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Sentiment Analysis Using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to make the sentiment analysis of IMDB Movie reviews. We will use a specialized RNN architecture called LSTM (Long Short Term Memory). With this lecture, we will inspect the basic methods that are used in NLP. **Note that some steps are exceptional for this basic task and should not be generalized.**\n",
    "You can find the dataset here: <br>\n",
    "https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a clean classification of words we need to convert all to words to same structure, which is lower or upper case. For a clear output, we modify sentiment to be 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one of the other reviewers has mentioned that ...          1\n",
       "1  a wonderful little production. <br /><br />the...          1\n",
       "2  i thought this was a wonderful way to spend ti...          1\n",
       "3  basically there's a family where a little boy ...          0\n",
       "4  petter mattei's \"love in the time of money\" is...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make lower case the reviews\n",
    "df['review'] = df['review'].apply(lambda x: x.lower())\n",
    "## convert sentiments to integer value positive = 1, negative = 0\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: int(x=='positive'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can inspect, there are additional information such as HTML tags and punctuations. We also get rid of them to achieve a clear input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production  the filming tec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there s a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei s  love in the time of money  is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one of the other reviewers has mentioned that ...          1\n",
       "1  a wonderful little production  the filming tec...          1\n",
       "2  i thought this was a wonderful way to spend ti...          1\n",
       "3  basically there s a family where a little boy ...          0\n",
       "4  petter mattei s  love in the time of money  is...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clean review text from html tags like <br/> \n",
    "df['review'] = df['review'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
    "## remove non letter and space characters from reviews (like punctuations, special characters)\n",
    "df['review'] = df['review'].apply(lambda x: re.sub(r'[^a-zA-Z]',' ',x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many stopwords in English, which do not add additional meaning to a sentence, but connect the words. We also get rid of them to reduce the workload of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove stop words \n",
    "## nltk english stopwords for preprocessing step\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(sentence, stopwords):\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stopwords]\n",
    "    \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: remove_stopwords(x, STOPWORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewers mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example of a review after preprocessing\n",
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains movie reviews. Thus, there are many character names, place names, etc. We take the most common 1000 words in order to reduce the workload of our model, so that our model does not waste time with less common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the longest review: 1416\n"
     ]
    }
   ],
   "source": [
    "## take 80% of data as train data, the rest is for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "from collections import Counter\n",
    "corpus = Counter()\n",
    "X_train.str.lower().str.split().apply(corpus.update)\n",
    "\n",
    "corpus_trashed = sorted(corpus, key=corpus.get, reverse=True)[0:1000]\n",
    "\n",
    "words=corpus_trashed\n",
    "\n",
    "## find the number of words in the dictionary of this data\n",
    "#words = pd.Series(' '.join(X_train).split()).unique()\n",
    "words_dict = {}\n",
    "for index, word in enumerate(words):\n",
    "    words_dict[word] = index+1\n",
    "    \n",
    "df['word_count'] = df['review'].apply(lambda x: len(x.split()))\n",
    "print(f'Length of the longest review: {df[\"word_count\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Padding\n",
    "Neural networks can not process text data. If we want to make computer understand words, we need to convert it to numbers. This is where tokenization takes place. Tokenization is the process of converting words (or letters) to numbers. It does so by indexing every word in a vocabulary to a corresponding number and uses it to transform that word to a vector afterwards.\n",
    "<br>For example the sequence of ['I', 'love', 'data', 'science'] transforms into [5, 64, 22, 103]. So that, model can understand which node a word represents.<br>\n",
    "In more in-depth, it uses indexes to create a one-hot vector. However, pytorch enables us to use index numbers to train model in more memory efficient way.\n",
    "<br>\n",
    "In the other hand, padding is not as crucial as tokenization. It solves the batch multiplication problem. When we are working with batches, we want every row to be the same length. However, different paragraphs have different lengths, so we compansate the difference of size with zeros.\n",
    "<br>\n",
    "For example if we have a maximum lenght of 10, we change the series [5, 64, 22, 103] into [0, 0, 0, 0, 0, 0, 5, 64, 22, 103]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = df[\"word_count\"].max() ## this can be changed according to the longest review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## assign an index to words\n",
    "def tokenize(word):\n",
    "    global words_dict\n",
    "    try:\n",
    "        return words_dict[word]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    \n",
    "def preprocess(seq):\n",
    "    return [tokenize(word) for word in seq.split()]\n",
    "\n",
    "## padding the reviews according to the given MAX_SEQ_LENGTH in order to create review matrix by making lengths of the reviews equal\n",
    "def pad_seq(seq, max_length):\n",
    "    #max_length = len(max(seq,key=len))\n",
    "    \n",
    "    tensor = np.zeros((len(seq), max_length))\n",
    "    for i, sentence in enumerate(seq):\n",
    "        review_len = len(sentence)\n",
    "        if review_len <= max_length:\n",
    "            zeroes = list(np.zeros(max_length-review_len))\n",
    "            sentence = zeroes+sentence\n",
    "        elif review_len > max_length:\n",
    "            sentence = sentence[0:max_length]\n",
    "        \n",
    "        tensor[i,:] = np.array(sentence)\n",
    "        \n",
    "    return torch.tensor(tensor, dtype=torch.long).to(device)\n",
    "\n",
    "## tokenization\n",
    "X_train = [preprocess(x) for x in X_train]\n",
    "X_test = [preprocess(x) for x in X_test]\n",
    "\n",
    "## padding\n",
    "X_train = pad_seq(X_train, MAX_SEQ_LENGTH)\n",
    "X_test = pad_seq(X_test, MAX_SEQ_LENGTH)\n",
    "\n",
    "## convert labels from dataframe to tensor\n",
    "y_train = torch.tensor(y_train.to_numpy().reshape((-1,1)), dtype=torch.float).to(device)\n",
    "y_test = torch.tensor(y_test.to_numpy().reshape((-1,1)), dtype=torch.float).to(device)\n",
    "\n",
    "## 64 batch data loader\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_set = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper parameters\n",
    "EMB_DIM = 64 ## dimension of 1 embedding vector\n",
    "HIDDEN_DIM = 256 ## dimension of dense layer\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        global words\n",
    "        input_dim = len(words)+1\n",
    "        emb_dim = EMB_DIM\n",
    "        hidden_dim = HIDDEN_DIM\n",
    "  \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim) ## embedding layer [numberofwords, embeddingdimension]\n",
    "        self.lstm = nn.LSTM(emb_dim,hidden_dim,batch_first=True) ## lstm layer\n",
    "        self.dropout = nn.Dropout(0.3) ## drop 30% of neural units\n",
    "        self.fc = nn.Linear(hidden_dim, 1) ## fully connected layer\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        embeds = self.embedding(batch) \n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = F.sigmoid(self.fc(out))[:,-1,:] ## output layer is sigmoid because it is a binary classification problem\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\tLoss:0.6035\tValidation Loss:0.5514\n",
      "Epoch 2/5\tLoss:0.4735\tValidation Loss:0.3941\n",
      "Epoch 3/5\tLoss:0.3648\tValidation Loss:0.3386\n",
      "Epoch 4/5\tLoss:0.3285\tValidation Loss:0.3400\n",
      "Epoch 5/5\tLoss:0.3045\tValidation Loss:0.3296\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model().to(device) ## load model to device (if gpu exists, it loads to gpu, otherwise, to cpu)\n",
    "loss_function = nn.BCELoss() ## loss function is binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters()) ## optimizer is adam\n",
    "\n",
    "epochs = EPOCHS\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_sum = 0\n",
    "    model.train()\n",
    "    for i, (sentence, sentiment) in enumerate(train_loader):\n",
    "        model.zero_grad()\n",
    "        output = model(sentence)\n",
    "        loss = loss_function(output, sentiment)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\\tLoss:{loss_sum/(i+1):.4f}\\t({100*(i+1)/len(train_loader):.0f}%)\", end='\\r')\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (sentence, sentiment) in enumerate(test_loader):\n",
    "            output = model(sentence)\n",
    "            loss = loss_function(output, sentiment)\n",
    "            valid_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\\tLoss:{loss_sum/len(train_loader):.4f}\\tValidation Loss:{valid_loss/len(test_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [] ## ground truth labels\n",
    "y_pred = [] ## predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in this loop, prediction is performed batch by batch\n",
    "for sentence, sentiment in test_loader:\n",
    "    \n",
    "    sentence = sentence.to(device)\n",
    "    sentiment = sentiment.to(device)\n",
    "    \n",
    "    batch_size = sentiment.shape[0]\n",
    "    \n",
    "    ## make prediction for 1 batch\n",
    "    pred = model(sentence)\n",
    "    \n",
    "    sentiment = sentiment.detach().cpu().numpy()\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        y_true.append(sentiment[i])\n",
    "        y_pred.append(pred[i,:])\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred = np.where(y_pred>0.5, 1, 0) ## since prediction results are originally a probability value,\n",
    "                                  ## we need to convert it into integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8583\n",
      "Conf Matrix: [[4004  957]\n",
      " [ 460 4579]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"Conf Matrix: \" + str(confusion_matrix(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, do not forget to save you model if you are happy with your results :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"sentiment_imdb.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Using the methods above, create a model which classifies messages as spam or not. Data set is given below.\n",
    "<br>\n",
    "https://www.kaggle.com/ozlerhakan/spam-or-not-spam-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
